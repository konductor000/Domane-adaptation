{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00a321d9da8d4be1acbe81a0ac893f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c07a56c570574a358c892517148c9284",
              "IPY_MODEL_6403de35bdb74879a7ba0edc91d811f0",
              "IPY_MODEL_e8391e2be6184d8f99ff944df92350aa"
            ],
            "layout": "IPY_MODEL_447c16554d704d1c88c0c5ff57f6acc1"
          }
        },
        "c07a56c570574a358c892517148c9284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6e3c81d53224de28e918428ccd16d5d",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb20d37c8f34600bcb61a32cfbeb7aa",
            "value": "100%"
          }
        },
        "6403de35bdb74879a7ba0edc91d811f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_980dc41b39324e2fbd632d31cef76ed0",
            "max": 107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89721007d57f460eb950336c947b39d6",
            "value": 107
          }
        },
        "e8391e2be6184d8f99ff944df92350aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe595b5754c54237b895388f65b204f8",
            "placeholder": "​",
            "style": "IPY_MODEL_59e9e74364ed4769902b03c2dc9e202e",
            "value": " 107/107 [00:20&lt;00:00,  4.67it/s]"
          }
        },
        "447c16554d704d1c88c0c5ff57f6acc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6e3c81d53224de28e918428ccd16d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb20d37c8f34600bcb61a32cfbeb7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "980dc41b39324e2fbd632d31cef76ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89721007d57f460eb950336c947b39d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe595b5754c54237b895388f65b204f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e9e74364ed4769902b03c2dc9e202e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bca88afe2242409ab3a77827e392b7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7e83e3f82144061b9e0989a14ceaf01",
              "IPY_MODEL_092e88006f75476fa7d474fcac37688b",
              "IPY_MODEL_3c57e0d6d7c04f4dae12f58212f7cfe4"
            ],
            "layout": "IPY_MODEL_bab8bc2664da4e9084c2cdea8869dd39"
          }
        },
        "a7e83e3f82144061b9e0989a14ceaf01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5579c986ae9d4039a66475bcdaac955c",
            "placeholder": "​",
            "style": "IPY_MODEL_5a2ef0c6048a4f2ea3b69ef7fe634505",
            "value": "100%"
          }
        },
        "092e88006f75476fa7d474fcac37688b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdd5a4235dd437eb5ec5cd21e833ea4",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_865849e967174b2a996c3fa0729da9e2",
            "value": 500
          }
        },
        "3c57e0d6d7c04f4dae12f58212f7cfe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98b09756277c4bf1b73d5302f0ef5152",
            "placeholder": "​",
            "style": "IPY_MODEL_6ea69114a8574badab9e9f280a29d2df",
            "value": " 500/500 [00:43&lt;00:00, 10.73ba/s]"
          }
        },
        "bab8bc2664da4e9084c2cdea8869dd39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5579c986ae9d4039a66475bcdaac955c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a2ef0c6048a4f2ea3b69ef7fe634505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bdd5a4235dd437eb5ec5cd21e833ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865849e967174b2a996c3fa0729da9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98b09756277c4bf1b73d5302f0ef5152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea69114a8574badab9e9f280a29d2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konductor000/Domane-adaptation/blob/main/domain_adaptation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install scattertext\n",
        "!pip install seqeval\n",
        "!pip install neptune-client"
      ],
      "metadata": {
        "id": "XqtASSVS_AvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import neptune.new as neptune\n",
        "\n",
        "run = neptune.init(\n",
        "    project=\"skorodumov000/ysda-hw5\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzNjhiZWIzNC03YjVmLTRiZmEtYTY1OS1lNTZmZDIzOWViOGQifQ==\",)"
      ],
      "metadata": {
        "id": "oKAPzU7wWhs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i1ClX_p8L1F"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import typing as tp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conll = datasets.load_dataset(\"conll2003\")\n",
        "wnut = datasets.load_dataset(\"wnut_17\")"
      ],
      "metadata": {
        "id": "Pvgi4dPM9HYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8uYsS72tuH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "inspect.getmro(type(conll))"
      ],
      "metadata": {
        "id": "erOF-gMN9Haa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conll.keys(), wnut.keys())"
      ],
      "metadata": {
        "id": "-SjJMPOd9Hc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll[\"test\"].features"
      ],
      "metadata": {
        "id": "sBGvPiMt9HfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll[\"test\"].dataset_size, len(conll[\"test\"])"
      ],
      "metadata": {
        "id": "lYBPLcVQ9Hhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll[\"test\"][50]"
      ],
      "metadata": {
        "id": "wRnPi_K59Hj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's view available tags\n",
        "CONLL_NER_TAGS = conll['train'].features['ner_tags'].feature.names\n",
        "print(CONLL_NER_TAGS)"
      ],
      "metadata": {
        "id": "F0-t-IRL9Hmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnut['test'].features"
      ],
      "metadata": {
        "id": "daky1tLf9HpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnut[\"test\"].dataset_size, len(wnut[\"test\"])"
      ],
      "metadata": {
        "id": "VRr5qcsw9HrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wnut[\"test\"][50])"
      ],
      "metadata": {
        "id": "RGdRJQtp9HtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WNUT_NER_TAGS = wnut['train'].features['ner_tags'].feature.names\n",
        "print(WNUT_NER_TAGS)"
      ],
      "metadata": {
        "id": "11C0EL2Z9Hvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "fW-8i2JY9HyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_render(tokens: tp.Sequence[str], ner_tags: tp.Sequence[str], \n",
        "               tags_list=CONLL_NER_TAGS, title: tp.Optional[str] = None, **kwargs):\n",
        "    pos = 0\n",
        "    ents = []\n",
        "    for word, tag_ in zip(tokens, ner_tags):\n",
        "        tag = tags_list[tag_]\n",
        "        if tag.startswith('B'):\n",
        "            ents.append({\n",
        "                \"start\": pos,\n",
        "                \"end\": pos + len(word),\n",
        "                \"label\": tag.split(\"-\")[1]\n",
        "            })\n",
        "        elif tag.startswith('I'):\n",
        "            ents[-1][\"end\"] = pos + len(word)\n",
        "        pos += (len(word) + 1)\n",
        "    displacy.render({\n",
        "        \"text\": \" \".join(tokens),\n",
        "        \"ents\": ents,\n",
        "        \"title\": title\n",
        "    }, style=\"ent\", manual=True)\n",
        "            "
      ],
      "metadata": {
        "id": "IzV8UTDF9H0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll[\"test\"][50]"
      ],
      "metadata": {
        "id": "pv3FgPTq9H3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test_id in [50, 200]:\n",
        "    ner_render(**conll[\"test\"][test_id], tags_list=CONLL_NER_TAGS, title = f'conll[{test_id}]')"
      ],
      "metadata": {
        "id": "dw7oR8HZ9H5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test_id in [100, 142]:\n",
        "    ner_render(**wnut[\"test\"][test_id], tags_list=WNUT_NER_TAGS, title = f'wnut[{test_id}]')"
      ],
      "metadata": {
        "id": "uPVzc8ex9H8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "from collections import Counter\n",
        "\n",
        "# Count every type of tag in CONLL and WNUT datasets:\n",
        "\n",
        "conll_tag_counts = Counter()\n",
        "wnut_tag_counts = Counter()\n",
        "\n",
        "for data in conll[\"test\"]:\n",
        "    for label in data['ner_tags']:\n",
        "        conll_tag_counts[CONLL_NER_TAGS[label]] += 1\n",
        "\n",
        "for data in wnut[\"test\"]:\n",
        "    for label in data['ner_tags']:\n",
        "        wnut_tag_counts[WNUT_NER_TAGS[label]] += 1"
      ],
      "metadata": {
        "id": "2AMZ7NXb9H_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnut_tag_counts"
      ],
      "metadata": {
        "id": "LVI2zlrB9IB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_tag_counts"
      ],
      "metadata": {
        "id": "sOHXB0OJ9IEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {\n",
        "    'O': 'O',\n",
        "    'B-location': 'B-LOC',\n",
        "    'I-location': 'I-LOC',\n",
        "    'B-group': 'B-ORG',\n",
        "    'B-corporation': 'B-ORG',\n",
        "    'B-person': 'B-PER',\n",
        "    'B-creative-work': 'B-MISC',\n",
        "    'B-product': 'B-MISC',\n",
        "    'I-person': 'I-PER',\n",
        "    'I-creative-work': 'I-MISC',\n",
        "    'I-corporation': 'I-ORG',\n",
        "    'I-group': 'I-ORG',\n",
        "    'I-product': 'I-MISC'\n",
        "}\n",
        "\n",
        "labelindexmapping = {WNUT_NER_TAGS.index(k):CONLL_NER_TAGS.index(v) for k, v in label_mapping.items()}\n",
        "print(labelindexmapping)"
      ],
      "metadata": {
        "id": "f1v63FWP9IG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_label_sequence(example: tp.Dict[str, tp.Any], label_mapping: tp.Dict[str, str]) -> tp.Dict[str, tp.Any]:\n",
        "    converted_example = dict(**example)\n",
        "    converted_example['ner_tags'] = [label_mapping[label] for label in example['ner_tags']]\n",
        "    return converted_example"
      ],
      "metadata": {
        "id": "ghEz8XVH9IJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_wnut = wnut.map(lambda x: convert_label_sequence(x, labelindexmapping))"
      ],
      "metadata": {
        "id": "Bp5HdXIw9IL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1, 2, 3]:\n",
        "    ner_render(**wnut[\"train\"][i], tags_list=WNUT_NER_TAGS, title = f'wnut_train_[{i}]')"
      ],
      "metadata": {
        "id": "mVZ-6TLg9IOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1, 2, 3]:\n",
        "    ner_render(**converted_wnut[\"train\"][i], tags_list=CONLL_NER_TAGS, \n",
        "               title = f'converted_wnut_train_[{i}]')"
      ],
      "metadata": {
        "id": "YCYQdSx-9IRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, IFrame\n",
        "HTML(\"<style>.container { width:98% !important; }</style>\")\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline "
      ],
      "metadata": {
        "id": "Mm_Fd-Z_9IUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scattertext as st\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "B-pIbFzu9IW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_df = pd.DataFrame([{\"text\": \" \".join(example[\"tokens\"]), \"ner\": example[\"ner_tags\"], \"dataset\": \"conll\"} for example in conll[\"train\"]])\n",
        "wnut_df = pd.DataFrame([{\"text\": \" \".join(example[\"tokens\"]), \"ner\": example[\"ner_tags\"], \"dataset\": \"wnut\"} for example in converted_wnut[\"train\"]])"
      ],
      "metadata": {
        "id": "NSc89_Mh9IZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([conll_df, wnut_df])\n",
        "df['parse'] = df.text.apply(st.whitespace_nlp_with_sentences)\n",
        "corpus = st.CorpusFromParsedDocuments(df, category_col='dataset', parsed_col='parse') \\\n",
        "    .build().get_unigram_corpus().compact(st.AssociationCompactor(2000))"
      ],
      "metadata": {
        "id": "wDuzTlKE9IcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.option_context('mode.chained_assignment', None):\n",
        "    # scattertext has pd.SettingWithCopyWarning in ScatterChart._add_term_freq_to_json_df\n",
        "    html = st.produce_scattertext_explorer(\n",
        "        corpus,\n",
        "        category='conll', category_name='CONLL', not_category_name='WNUT',\n",
        "        minimum_term_frequency=0, pmi_threshold_coefficient=0,\n",
        "        width_in_pixels=1000,\n",
        "        transform=st.Scalers.dense_rank\n",
        "    )\n",
        "\n",
        "with open(\"difference.html\", \"w\", encoding=\"utf-8\") as outf:\n",
        "    print(html, file=outf)"
      ],
      "metadata": {
        "id": "pWLmyEYL9Ie8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IFrame(\"difference.html\", width=1200, height=1000)"
      ],
      "metadata": {
        "id": "OOFO_gA89Ihn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch \n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "hL4FZVtT9Ikd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (pipeline, \n",
        "        AutoModelForTokenClassification, AutoTokenizer, \n",
        "        BertForTokenClassification, BertTokenizer)\n",
        "\n",
        "# Load pretrained model and tokenizer for English NER task (dslim/bert-base-NER)\n",
        "\n",
        "checkpoint = 'dslim/bert-base-NER'\n",
        "model = AutoModelForTokenClassification.from_pretrained(checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
      ],
      "metadata": {
        "id": "ObblapD69InO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspect.getmro(type(model))"
      ],
      "metadata": {
        "id": "ztG3fv9k9Ip0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "id": "Kk4pB-X89Isy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "id": "8vZwHatq9IvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.bert"
      ],
      "metadata": {
        "id": "33P1drnY9IyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_render(**conll[\"test\"][10], tags_list=CONLL_NER_TAGS)"
      ],
      "metadata": {
        "id": "MGBwyhqj9I0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizer(conll[\"test\"][10][\"tokens\"], is_split_into_words=True)"
      ],
      "metadata": {
        "id": "fEbxFoNH9I3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original sentence:\\n---\\n{' '.join(conll['test'][10]['tokens'])}\")\n",
        "\n",
        "tokenized = \" \".join([tokenizer.convert_ids_to_tokens(id_) for id_ in encoded[\"input_ids\"]])\n",
        "print(f\"\\nTokenized sentence:\\n---\\n{tokenized}\")\n"
      ],
      "metadata": {
        "id": "0hpwTIQO9I6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_preserve_tags(example: tp.Dict[str, tp.Any],\n",
        "                               tokenizer: BertTokenizer,\n",
        "                               label2id: tp.Dict[str, int],\n",
        "                               tokenizer_params={}) -> tp.Dict[str, tp.Any]:\n",
        "    # write your own function to split each pair of word-token to same number of pieces.\n",
        "    encoded = tokenizer(example[\"tokens\"], is_split_into_words=True, **tokenizer_params)\n",
        "    encoded.update(example)\n",
        "    conll2ner = [label2id[i] for i in CONLL_NER_TAGS]\n",
        "    id2label = {label2id[i]: i for i in label2id}\n",
        "    \n",
        "    raw_label_id = 0\n",
        "    encoded['labels'] = []\n",
        "    curr_token = ''\n",
        "    for i in encoded[\"input_ids\"]:\n",
        "        #print()\n",
        "        decoded = tokenizer.decode(i)\n",
        "        #print(decoded, '++', curr_token, '++', end=' | ')\n",
        "        if decoded in ['[CLS]', '[SEP]']:\n",
        "            encoded['labels'].append(0)\n",
        "            #print('start or end', end=' | ')\n",
        "            continue\n",
        "\n",
        "        assert len(encoded['labels']) != 0\n",
        "        prev_label = encoded['labels'][-1]\n",
        "        prev_label_text = id2label[prev_label]\n",
        "        #print(prev_label, prev_label_text, end=' | ', sep=' / ')\n",
        "        if decoded.startswith(\"##\"):\n",
        "            decoded = decoded[2:]\n",
        "        \n",
        "        if len(curr_token) == 0:\n",
        "            encoded['labels'].append(conll2ner[example['ner_tags'][raw_label_id]])\n",
        "            #print('00100', encoded['labels'][-1], '/', id2label[encoded['labels'][-1]], end=' | ')\n",
        "        else:\n",
        "            encoded['labels'].append(prev_label if prev_label_text.startswith(\"O\") or \\\n",
        "                                     prev_label_text.startswith(\"I\") else prev_label + 1)\n",
        "            #print('00200', encoded['labels'][-1], '/', id2label[encoded['labels'][-1]], end=' | ')\n",
        "        \n",
        "        curr_token += decoded\n",
        "        if len(curr_token) == len(encoded['tokens'][raw_label_id]):\n",
        "            #print('00300', end=' | ')\n",
        "            curr_token = ''\n",
        "            raw_label_id += 1\n",
        "        \n",
        "        \n",
        "\n",
        "    encoded['text_labels'] = [id2label[i] for i in encoded['labels']]\n",
        "    \n",
        "    #print(encoded)\n",
        "        \n",
        "    assert len(encoded['labels']) == len(encoded[\"input_ids\"])\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "Zh1O-qwO9I89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"AL-AIN, United Arab Emirates 1996-12-06\"\n",
        "test_example = {\"tokens\": ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06'], \"ner_tags\": [5, 0, 5, 6, 6, 0]}\n",
        "test_result = tokenize_and_preserve_tags(test_example, tokenizer, model.config.label2id)\n",
        "\n",
        "print(tokenizer.decode(test_result['input_ids']))\n",
        "\n",
        "assert tokenizer.decode(test_result['input_ids']) == '[CLS] AL - AIN, United Arab Emirates 1996 - 12 - 06 [SEP]'\n",
        "\n",
        "print(test_result['text_labels'])\n",
        "\n",
        "assert test_result['text_labels'] == ['O'] + ['B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O'] + [\"O\"]\n",
        "\n",
        "assert test_result['labels'] == [0, 7, 8, 8, 8, 0, 7, 8, 8, 0, 0, 0, 0, 0, 0]"
      ],
      "metadata": {
        "id": "Ko5WFCOr9I_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"His name is Jerry Abrahamson\"\n",
        "test_example = {\"tokens\": test_sentence.split(\" \"), \"ner_tags\": [0, 0, 0, 1, 2]}\n",
        "test_result = tokenize_and_preserve_tags(test_example, tokenizer, model.config.label2id)\n",
        "\n",
        "assert tokenizer.decode(test_result['input_ids']) == '[CLS] His name is Jerry Abrahamson [SEP]'\n",
        "\n",
        "                                     #CLS     His  name is    Jerry    Abraham   ##son      SEP\n",
        "assert test_result['text_labels'] == ['O'] + [\"O\", \"O\", \"O\", \"B-PER\", \"I-PER\",  \"I-PER\"] + [\"O\"]\n",
        "\n",
        "assert test_result['labels'] == [0, 0, 0, 0, 3, 4, 4, 0]"
      ],
      "metadata": {
        "id": "wkFyxINv9JCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll = conll.map(lambda x: tokenize_and_preserve_tags(x, tokenizer, model.config.label2id))"
      ],
      "metadata": {
        "id": "o22d0iGy9JFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnut = converted_wnut\n",
        "wnut = wnut.map(lambda x: tokenize_and_preserve_tags(x, tokenizer, model.config.label2id))"
      ],
      "metadata": {
        "id": "SXXB_Ha89JHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'], output_all_columns=True)\n",
        "wnut.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'], output_all_columns=True)"
      ],
      "metadata": {
        "id": "BO4QOeNA9JKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "class PadSequence:\n",
        "    def __init__(self, padded_columns, device=device):\n",
        "        self.padded_columns = set(padded_columns)\n",
        "        self.device = device\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        padded_batch = defaultdict(list)\n",
        "        for example in batch:\n",
        "            for key, tensor in example.items():\n",
        "                padded_batch[key].append(tensor)\n",
        "                \n",
        "        for key, val in padded_batch.items():\n",
        "            if key in self.padded_columns:\n",
        "                padded_batch[key] = torch.nn.utils.rnn.pad_sequence(val, batch_first=True).to(self.device)\n",
        "        return padded_batch"
      ],
      "metadata": {
        "id": "DFw49rTn9JNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_test_dataloader = torch.utils.data.DataLoader(conll[\"test\"], batch_size=4, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))"
      ],
      "metadata": {
        "id": "J8K79fu-9JQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch = next(iter(conll_test_dataloader))\n",
        "\n",
        "to_change = ['input_ids', 'token_type_ids', 'attention_mask', 'labels']\n",
        "\n",
        "for i in to_change:\n",
        "    for j in test_batch[i]:\n",
        "        j.to(device)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model_output = model(input_ids=test_batch[\"input_ids\"],\n",
        "                     token_type_ids=test_batch[\"token_type_ids\"],\n",
        "                     attention_mask=test_batch[\"attention_mask\"],\n",
        "                     labels=test_batch[\"labels\"], return_dict=True)"
      ],
      "metadata": {
        "id": "wXVKcOlX9JTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NamedEntityPredictor:\n",
        "    def __init__(self,\n",
        "                 model: BertForTokenClassification,\n",
        "                 tokenizer: BertTokenizer,\n",
        "                 id2label: tp.Optional[tp.Dict[str, int]] = None):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.id2label = model.config.id2label if id2label is None else id2label\n",
        "    \n",
        "    def predict(self, batch: tp.Dict[str, tp.Any]):\n",
        "        \n",
        "        self.model.eval()\n",
        "\n",
        "        to_change = ['input_ids', 'token_type_ids', 'attention_mask', 'labels']\n",
        "\n",
        "        for i in to_change:\n",
        "            for j in test_batch[i]:\n",
        "                j.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model_output = self.model(input_ids=batch[\"input_ids\"],\n",
        "                                      token_type_ids=batch[\"token_type_ids\"],\n",
        "                                      attention_mask=batch[\"attention_mask\"],\n",
        "                                      labels=batch[\"labels\"],\n",
        "                                      return_dict=True)\n",
        "        indices = torch.argmax(model_output.logits, axis=2)\n",
        "        indices = indices.detach().cpu().numpy()\n",
        "        attention_mask = batch[\"attention_mask\"].cpu().numpy()\n",
        "        batch_size = len(batch[\"input_ids\"])\n",
        "        predicted_labels = []\n",
        "        for i in range(batch_size):\n",
        "            predicted_labels.append([self.id2label[id_] for id_ in indices[i][attention_mask[i] == 1]])\n",
        "            \n",
        "        return {\n",
        "            \"predicted_labels\": predicted_labels,\n",
        "            \"loss\": model_output.loss,\n",
        "            \"logits\": model_output.logits\n",
        "        }"
      ],
      "metadata": {
        "id": "uIVk-Srm9JV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner = NamedEntityPredictor(model.to(device), tokenizer)\n",
        "test_prediction = ner.predict(test_batch)\n",
        "\n",
        "assert test_prediction['predicted_labels'][2] == list(test_batch[\"text_labels\"][2])"
      ],
      "metadata": {
        "id": "Rs7TCnY9-Nd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report, f1_score\n",
        "\n",
        "\n",
        "def test_model(model, to_print=False):\n",
        "    conll_test_dataloader = torch.utils.data.DataLoader(conll[\"test\"], batch_size=16, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "    wnut_test_dataloader = torch.utils.data.DataLoader(wnut[\"test\"], batch_size=16, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "\n",
        "    model.eval()\n",
        "    ner = NamedEntityPredictor(model, tokenizer)\n",
        "    predicted_labels = {\"wnut_test\": [], \"conll_test\": []}\n",
        "\n",
        "    for batch in conll_test_dataloader:\n",
        "        predicted_labels[\"conll_test\"].extend(ner.predict(batch)[\"predicted_labels\"])\n",
        "        \n",
        "    for batch in wnut_test_dataloader:\n",
        "        predicted_labels[\"wnut_test\"].extend(ner.predict(batch)[\"predicted_labels\"])\n",
        "\n",
        "    conll_report = classification_report(y_true=[list(example[\"text_labels\"]) for example in conll[\"test\"]],\n",
        "                                                     y_pred=predicted_labels[\"conll_test\"])\n",
        "    \n",
        "    wnut_report = classification_report(y_true=[list(example[\"text_labels\"]) for example in wnut[\"test\"]],\n",
        "                                                    y_pred=predicted_labels[\"wnut_test\"])\n",
        "    \n",
        "    conll_f1 = f1_score(y_true=[list(example[\"text_labels\"])\n",
        "                                                             for example in conll[\"test\"]],\n",
        "                                                     y_pred=predicted_labels[\"conll_test\"])\n",
        "\n",
        "    wnut_f1 = f1_score(y_true=[list(example[\"text_labels\"])\n",
        "                                                             for example in wnut[\"test\"]],\n",
        "                                                     y_pred=predicted_labels[\"wnut_test\"])\n",
        "\n",
        "    if to_print:\n",
        "        print(f\"CONLL:\\n {conll_report}\")\n",
        "        print(f\"WNUT:\\n {wnut_report}\")\n",
        "\n",
        "    return predicted_labels, conll_f1, wnut_f1"
      ],
      "metadata": {
        "id": "-PmDr_Mhdb-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels, conll_f1, wnut_f1 = test_model(model, to_print=True)"
      ],
      "metadata": {
        "id": "VSyvdm34-Nsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_embeddings(model, batch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        return model.bert(input_ids=batch[\"input_ids\"],\n",
        "                          token_type_ids=batch[\"token_type_ids\"],\n",
        "                          attention_mask=batch[\"attention_mask\"],\n",
        "                          return_dict=True)[\"last_hidden_state\"].cpu().numpy()[:,0]"
      ],
      "metadata": {
        "id": "Pm4P0K0w-Nu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "conll_train_dataloader = torch.utils.data.DataLoader(conll[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "wnut_train_dataloader = torch.utils.data.DataLoader(wnut[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "\n",
        "for batch in tqdm(conll_train_dataloader):\n",
        "    X.append(get_sentence_embeddings(model, batch))\n",
        "    Y.extend([0] * len(batch[\"input_ids\"]))\n",
        "    \n",
        "for batch in tqdm(wnut_train_dataloader):\n",
        "    X.append(get_sentence_embeddings(model, batch))\n",
        "    Y.extend([1] * len(batch[\"input_ids\"]))"
      ],
      "metadata": {
        "id": "cUr_33Tz-Nxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate(X)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "hl1aS1ww-N0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_classifier = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
        "dataset_classifier.fit(X, Y)"
      ],
      "metadata": {
        "id": "RKxqQAX9-N3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnut_test_scores = []\n",
        "\n",
        "wnut_test_dataloader = torch.utils.data.DataLoader(wnut[\"test\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "for batch in tqdm(wnut_test_dataloader):\n",
        "    x = get_sentence_embeddings(model, batch)\n",
        "    wnut_test_scores.append(dataset_classifier.predict_proba(x)[:,1])\n",
        "    "
      ],
      "metadata": {
        "id": "aogncPp8-N5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnut_test_scores = np.concatenate(wnut_test_scores)"
      ],
      "metadata": {
        "id": "W574GsLV-N8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(wnut_test_scores)\n",
        "plt.xlabel(\"WNUT score.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ciYuWKFr-N_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_indices = np.argsort(wnut_test_scores)"
      ],
      "metadata": {
        "id": "Z0AEXWpF-OBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnut_predicted_labels = np.array(predicted_labels[\"wnut_test\"], dtype=object\n",
        "                                )[np.argsort(wnut_test_scores)]"
      ],
      "metadata": {
        "id": "e0mvcq-6-pD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnut_true_labels = np.array([list(example[\"text_labels\"]) for example in wnut[\"test\"]], dtype=object\n",
        "                           )[np.argsort(wnut_test_scores)]"
      ],
      "metadata": {
        "id": "RcHCXydb-pGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_splits = np.array_split(wnut_predicted_labels, 5, )\n",
        "true_splits = np.array_split(wnut_true_labels, 5)\n",
        "score_splits = np.array_split(wnut_test_scores[np.argsort(wnut_test_scores)], 5)"
      ],
      "metadata": {
        "id": "jUFi56jn-pIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"score\\tf1\")\n",
        "for scores, true_split, predicted_split in zip(score_splits, true_splits, predicted_splits):\n",
        "    mean_score = np.mean(scores)\n",
        "    f1 = f1_score(true_split, predicted_split)\n",
        "    print(f\"{mean_score:.3f}\\t{f1:.3f}\")"
      ],
      "metadata": {
        "id": "AmZ5Ygiw-pKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def train_model(num_epochs, model, dataset, model_name=''):\n",
        "    run[\"train/start\"] = datetime.now()\n",
        "\n",
        "    results = {\n",
        "        'model_f1_conll': [],\n",
        "        'model_f1_wnut': [],\n",
        "        'model_loss': []\n",
        "    }\n",
        "\n",
        "    num_training_steps = num_epochs * len(dataset)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps,\n",
        "    )\n",
        "    print(num_training_steps)\n",
        "\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch in dataset:\n",
        "\n",
        "            to_change = ['input_ids', 'token_type_ids', 'attention_mask', 'labels']\n",
        "            for key in to_change:\n",
        "                for tens in test_batch[key]:\n",
        "                    tens.to(device)\n",
        "\n",
        "            outputs = model(input_ids=batch[\"input_ids\"],\n",
        "                                        token_type_ids=batch[\"token_type_ids\"],\n",
        "                                        attention_mask=batch[\"attention_mask\"],\n",
        "                                        labels=batch[\"labels\"],\n",
        "                                        return_dict=True)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            epoch_loss += loss\n",
        "\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            progress_bar.update(1)\n",
        "\n",
        "        _, f1_conll, f1_wnut = test_model(model) \n",
        "        results['model_f1_conll'].append(f1_conll)\n",
        "        results['model_f1_wnut'].append(f1_wnut)\n",
        "        results['model_loss'].append(epoch_loss / len(dataset))\n",
        "\n",
        "        run[f\"train/{model_name}wnut_accuracy\"].log(f1_wnut)\n",
        "        run[f\"train/{model_name}conll_accuracy\"].log(f1_conll)\n",
        "        run[f\"train/{model_name}loss\"].log(epoch_loss / len(dataset))\n",
        "    \n",
        "    run[\"train/end\"] = datetime.now()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "f0N-mnW8-pMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25"
      ],
      "metadata": {
        "id": "-x-zfKrPZlPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "full_train_model = AutoModelForTokenClassification.from_pretrained(checkpoint)\n",
        "full_train_model.to(device)\n",
        "optimizer = AdamW(full_train_model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "rVjw6Ms7xg1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#full_results = train_model(num_epochs, full_train_model, wnut_train_dataloader)"
      ],
      "metadata": {
        "id": "LV5gCpVJ-pPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_train_model = AutoModelForTokenClassification.from_pretrained(checkpoint)\n",
        "class_train_model.to(device)\n",
        "optimizer = AdamW(class_train_model.parameters(), lr=5e-5)\n",
        "\n",
        "for param in class_train_model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "param.requires_grad = True\n",
        "print()"
      ],
      "metadata": {
        "id": "3dvZDsYC-pRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class_results = train_model(num_epochs, class_train_model, wnut_train_dataloader)"
      ],
      "metadata": {
        "id": "UbVwt6jd-pWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def class_dataset(conll, wnut):\n",
        "    X = []\n",
        "    Y = []\n",
        "    conll_X = []\n",
        "\n",
        "    conll_train_dataloader = torch.utils.data.DataLoader(conll[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask']))\n",
        "    wnut_train_dataloader = torch.utils.data.DataLoader(wnut[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask']))\n",
        "\n",
        "    print(len(conll_train_dataloader))\n",
        "    print(conll_train_dataloader)\n",
        "\n",
        "    for batch in tqdm(conll_train_dataloader):\n",
        "        X.append(get_sentence_embeddings(model, batch))\n",
        "        conll_X.append(get_sentence_embeddings(model, batch))\n",
        "        Y.extend([0] * len(batch[\"input_ids\"]))\n",
        "        \n",
        "    for batch in tqdm(wnut_train_dataloader):\n",
        "        X.append(get_sentence_embeddings(model, batch))\n",
        "        Y.extend([1] * len(batch[\"input_ids\"]))\n",
        "\n",
        "    X = np.concatenate(X)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    idx = np.random.permutation(range(len(Y)))\n",
        "\n",
        "    X = X[idx]\n",
        "    Y = Y[idx]\n",
        "\n",
        "    n = 5\n",
        "    splitted_X = np.array_split(X, n)\n",
        "    splitted_Y = np.array_split(Y, n)\n",
        "\n",
        "    conll_X = np.concatenate(conll_X)\n",
        "    preds = np.zeros(len(conll_X))\n",
        "\n",
        "    for i in range(n):\n",
        "        X_, Y_ = splitted_X[i], splitted_Y[i]\n",
        "        dataset_classifier = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
        "        dataset_classifier.fit(X_, Y_)\n",
        "\n",
        "        pred = np.array(dataset_classifier.predict_proba(conll_X))\n",
        "        preds += pred[:, 1]\n",
        "\n",
        "    preds /= (n - 1)\n",
        "\n",
        "    arg_idx = preds.argsort()[::-1][:(len(conll_X) // 4)]\n",
        "\n",
        "    return arg_idx"
      ],
      "metadata": {
        "id": "pNJ-TOl1-pT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arg_idx = class_dataset(conll, wnut)"
      ],
      "metadata": {
        "id": "YH9u9-RUeZV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_train_model = AutoModelForTokenClassification.from_pretrained(checkpoint)\n",
        "top_train_model.to(device)\n",
        "optimizer = AdamW(top_train_model.parameters(), lr=5e-5)\n",
        "\n",
        "conll_train_dataloader = torch.utils.data.DataLoader(np.array(conll[\"train\"])[arg_idx], \\\n",
        "                         batch_size=32, collate_fn=PadSequence(['input_ids', \\\n",
        "                         'token_type_ids', 'attention_mask', 'labels']))\n",
        "\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "qDGrM-XFbqas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_model(num_epochs, top_train_model, conll_train_dataloader, model_name='UnStop50/')"
      ],
      "metadata": {
        "id": "9GQeQaP7bqdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWofMDyxbqgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proxy_train_model = AutoModelForTokenClassification.from_pretrained(checkpoint)\n",
        "proxy_train_model.to(device)\n",
        "optimizer = AdamW(proxy_train_model.parameters(), lr=5e-5)\n",
        "\n",
        "wnut_train_dataloader = torch.utils.data.DataLoader(wnut[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "\n",
        "results = []\n",
        "num_epochs = 30"
      ],
      "metadata": {
        "id": "gDiRxlLXbqi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "proxy_train_model.eval()\n",
        "for batch in tqdm(wnut_train_dataloader):\n",
        "    with torch.no_grad():\n",
        "        outputs = proxy_train_model(input_ids=batch[\"input_ids\"],\n",
        "                                    token_type_ids=batch[\"token_type_ids\"],\n",
        "                                    attention_mask=batch[\"attention_mask\"],\n",
        "                                    labels=batch[\"labels\"],\n",
        "                                    return_dict=True)\n",
        "    \n",
        "    for j, single_out in enumerate(outputs['logits']):\n",
        "        new_labels = []\n",
        "        cnt = 0\n",
        "        score = 0\n",
        "        for logit in single_out:\n",
        "            srtd = np.argsort(logit.cpu().detach().numpy())[::-1]\n",
        "            new_labels.append(srtd[0])\n",
        "            if srtd[0] == 0:\n",
        "                continue\n",
        "            cnt += 1\n",
        "            score += logit[srtd[0]] - logit[srtd[1]]\n",
        "\n",
        "        results.append(float(score / max(1, cnt)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "00a321d9da8d4be1acbe81a0ac893f68",
            "c07a56c570574a358c892517148c9284",
            "6403de35bdb74879a7ba0edc91d811f0",
            "e8391e2be6184d8f99ff944df92350aa",
            "447c16554d704d1c88c0c5ff57f6acc1",
            "c6e3c81d53224de28e918428ccd16d5d",
            "fcb20d37c8f34600bcb61a32cfbeb7aa",
            "980dc41b39324e2fbd632d31cef76ed0",
            "89721007d57f460eb950336c947b39d6",
            "fe595b5754c54237b895388f65b204f8",
            "59e9e74364ed4769902b03c2dc9e202e"
          ]
        },
        "id": "zBuR-ULg8qG_",
        "outputId": "0b3f24b8-4f97-469c-acb1-ccbb9ffed99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/107 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00a321d9da8d4be1acbe81a0ac893f68"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.argsort(results)[::-1][:len(results) // 2]\n",
        "wnut_train_dataloader = torch.utils.data.DataLoader(np.array(wnut[\"train\"])[idx], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))"
      ],
      "metadata": {
        "id": "Hm4_wRTTbqll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_model(num_epochs, proxy_train_model, wnut_train_dataloader, model_name='UnStop50%/')"
      ],
      "metadata": {
        "id": "SJAizFzebqoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-I5GejOPqqfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "conll_X = []\n",
        "\n",
        "conll_train_dataloader = torch.utils.data.DataLoader(conll[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask']))\n",
        "wnut_train_dataloader = torch.utils.data.DataLoader(wnut[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask']))\n",
        "\n",
        "print(len(conll_train_dataloader))\n",
        "print(conll_train_dataloader)\n",
        "\n",
        "for batch in tqdm(conll_train_dataloader):\n",
        "    X.append(get_sentence_embeddings(model, batch))\n",
        "    conll_X.append(get_sentence_embeddings(model, batch))\n",
        "    Y.extend([0] * len(batch[\"input_ids\"]))\n",
        "    \n",
        "for batch in tqdm(wnut_train_dataloader):\n",
        "    X.append(get_sentence_embeddings(model, batch))\n",
        "    Y.extend([1] * len(batch[\"input_ids\"]))\n",
        "\n",
        "X = np.concatenate(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "idx = np.random.permutation(range(len(Y)))\n",
        "\n",
        "X = X[idx]\n",
        "Y = Y[idx]\n",
        "\n",
        "n = 5\n",
        "splitted_X = np.array_split(X, n)\n",
        "splitted_Y = np.array_split(Y, n)\n",
        "\n",
        "conll_X = np.concatenate(conll_X)\n",
        "preds = np.zeros(len(conll_X))\n",
        "\n",
        "dataset_classifier = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
        "dataset_classifier.fit(X, Y)"
      ],
      "metadata": {
        "id": "Z1a2xFJZqqh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ysda-seminars.s3.eu-central-1.amazonaws.com/reddit_sample.json\n",
        "reddit = datasets.load_dataset('json', data_files='reddit_sample.json')"
      ],
      "metadata": {
        "id": "FiiZFOd7qqkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(example):\n",
        "    out = tokenizer([' '.join(text or ['']) for text in example['words']], truncation='longest_first')\n",
        "    out['token_type_ids'] = [[1] * len(out['input_ids'][i]) for i in range(len(out['input_ids']))]\n",
        "\n",
        "    return out\n",
        "\n",
        "reddit = reddit.map(lambda example: encode(example), batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bca88afe2242409ab3a77827e392b7e2",
            "a7e83e3f82144061b9e0989a14ceaf01",
            "092e88006f75476fa7d474fcac37688b",
            "3c57e0d6d7c04f4dae12f58212f7cfe4",
            "bab8bc2664da4e9084c2cdea8869dd39",
            "5579c986ae9d4039a66475bcdaac955c",
            "5a2ef0c6048a4f2ea3b69ef7fe634505",
            "0bdd5a4235dd437eb5ec5cd21e833ea4",
            "865849e967174b2a996c3fa0729da9e2",
            "98b09756277c4bf1b73d5302f0ef5152",
            "6ea69114a8574badab9e9f280a29d2df"
          ]
        },
        "id": "uG7Sih8Bqqm2",
        "outputId": "9ef2252b-83c7-4c14-cc2d-6caabeb9f3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bca88afe2242409ab3a77827e392b7e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reddit.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask'], output_all_columns=True)"
      ],
      "metadata": {
        "id": "l45aIAayqqpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_train_dataloader = torch.utils.data.DataLoader(reddit[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'attention_mask', 'token_type_ids']))"
      ],
      "metadata": {
        "id": "2YJJ0ReQqqrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results = []\n",
        "# res = 0\n",
        "\n",
        "# model.eval()\n",
        "# for batch in tqdm(reddit_train_dataloader):\n",
        "#     with torch.no_grad():\n",
        "#         res = model.bert(input_ids=batch[\"input_ids\"],\n",
        "#                           token_type_ids=batch[\"token_type_ids\"],\n",
        "#                           attention_mask=batch[\"attention_mask\"],\n",
        "#                           return_dict=True)[\"last_hidden_state\"].cpu().numpy()[:,0]\n",
        "#     results.append(dataset_classifier.predict_proba(get_sentence_embeddings(model, batch)))"
      ],
      "metadata": {
        "id": "gCbQUKd8qqun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZPvppHGD1Qq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = 'drive/MyDrive/saves'"
      ],
      "metadata": {
        "id": "2_-fdN6F1P25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6G7CIV81P5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = torch.load(dir + '/res.pt')"
      ],
      "metadata": {
        "id": "hbTAqUyH5paK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = np.array(results)\n",
        "results = np.concatenate(results[:, :, 1])"
      ],
      "metadata": {
        "id": "9hJwpQ0FuJHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_res = np.argsort(results)[::-1][:10**5]"
      ],
      "metadata": {
        "id": "cv2HPOFIqq2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Masked LM training\"\"\""
      ],
      "metadata": {
        "id": "i3e9OxAdq2tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForMaskedLM\n",
        "\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "BnN8ytLNqq4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a great [MASK].\""
      ],
      "metadata": {
        "id": "62114NAzqq9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "gfRGIeBHqrAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"np\")\n",
        "token_logits = model(**inputs).logits\n",
        "# Find the location of [MASK] and extract its logits\n",
        "mask_token_index = np.argwhere(inputs[\"input_ids\"] == tokenizer.mask_token_id)[0, 1]\n",
        "mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "# Pick the [MASK] candidates with the highest logits\n",
        "# We negate the array before argsort to get the largest, not the smallest, logits\n",
        "top_5_tokens = np.argsort(-mask_token_logits)[:5].tolist()\n",
        "\n",
        "for token in top_5_tokens:\n",
        "    print(f\">>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}\")"
      ],
      "metadata": {
        "id": "D-_TqyzcxYME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "imdb_dataset"
      ],
      "metadata": {
        "id": "1bMhGEapxYOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ysda-seminars.s3.eu-central-1.amazonaws.com/reddit_sample.json\n",
        "reddit = datasets.load_dataset('json', data_files='reddit_sample.json')\n",
        "\n",
        "reddit['train'] = reddit['train'].select(idx_res)"
      ],
      "metadata": {
        "id": "2sLSpD7asvbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    result = tokenizer([\" \".join(text) for text in examples[\"words\"]])\n",
        "    if tokenizer.is_fast:\n",
        "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
        "    return result\n",
        "\n",
        "\n",
        "# Use batched=True to activate fast multithreading!\n",
        "tokenized_datasets = reddit.map(\n",
        "    tokenize_function, batched=True, remove_columns=[\"words\"]\n",
        ")\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "id": "Q5ozpqA-pw41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "-0TKShqKpw7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 128"
      ],
      "metadata": {
        "id": "qk9ssidBpw9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing produces a list of lists for each feature\n",
        "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
        "\n",
        "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
        "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
      ],
      "metadata": {
        "id": "gAV3wKx3pw_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated_examples = {\n",
        "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
        "}\n",
        "total_length = len(concatenated_examples[\"input_ids\"])\n",
        "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
      ],
      "metadata": {
        "id": "4AIrYm_LpxCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = {\n",
        "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "    for k, t in concatenated_examples.items()\n",
        "}\n",
        "\n",
        "for chunk in chunks[\"input_ids\"]:\n",
        "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
      ],
      "metadata": {
        "id": "3WuhyCx6pxFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_texts(examples):\n",
        "    # Concatenate all texts\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    # Compute length of concatenated texts\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the last chunk if it's smaller than chunk_size\n",
        "    total_length = (total_length // chunk_size) * chunk_size\n",
        "    # Split by chunks of max_len\n",
        "    result = {\n",
        "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    # Create a new labels column\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ],
      "metadata": {
        "id": "WzL1YZH6pxIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
        "lm_datasets"
      ],
      "metadata": {
        "id": "oCVea2G1pxLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
      ],
      "metadata": {
        "id": "G8r6y1znpxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(lm_datasets[\"train\"][1][\"labels\"])"
      ],
      "metadata": {
        "id": "9kowNERDpxRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
      ],
      "metadata": {
        "id": "ZPOgxrDVpxVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
        "for sample in samples:\n",
        "    _ = sample.pop(\"word_ids\")\n",
        "\n",
        "for chunk in data_collator(samples)[\"input_ids\"]:\n",
        "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
      ],
      "metadata": {
        "id": "3aSeqThNpxZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "from transformers.data.data_collator import tf_default_data_collator\n",
        "\n",
        "wwm_probability = 0.2\n",
        "\n",
        "\n",
        "def whole_word_masking_data_collator(features):\n",
        "    for feature in features:\n",
        "        word_ids = feature.pop(\"word_ids\")\n",
        "\n",
        "        # Create a map between words and corresponding token indices\n",
        "        mapping = collections.defaultdict(list)\n",
        "        current_word_index = -1\n",
        "        current_word = None\n",
        "        for idx, word_id in enumerate(word_ids):\n",
        "            if word_id is not None:\n",
        "                if word_id != current_word:\n",
        "                    current_word = word_id\n",
        "                    current_word_index += 1\n",
        "                mapping[current_word_index].append(idx)\n",
        "\n",
        "        # Randomly mask words\n",
        "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
        "        input_ids = feature[\"input_ids\"]\n",
        "        labels = feature[\"labels\"]\n",
        "        new_labels = [-100] * len(labels)\n",
        "        for word_id in np.where(mask)[0]:\n",
        "            word_id = word_id.item()\n",
        "            for idx in mapping[word_id]:\n",
        "                new_labels[idx] = labels[idx]\n",
        "                input_ids[idx] = tokenizer.mask_token_id\n",
        "        feature[\"labels\"] = new_labels\n",
        "\n",
        "    return tf_default_data_collator(features)"
      ],
      "metadata": {
        "id": "j4J7kOwApxdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
        "batch = whole_word_masking_data_collator(samples)\n",
        "\n",
        "for chunk in batch[\"input_ids\"]:\n",
        "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
      ],
      "metadata": {
        "id": "L-WjdCoqpxgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 10_000\n",
        "test_size = int(0.1 * train_size)\n",
        "\n",
        "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
        "    train_size=train_size, test_size=test_size, seed=42\n",
        ")\n",
        "downsampled_dataset"
      ],
      "metadata": {
        "id": "Whaw4IPqpxj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_dataset = model.prepare_tf_dataset(\n",
        "    downsampled_dataset[\"train\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "tf_eval_dataset = model.prepare_tf_dataset(\n",
        "    downsampled_dataset[\"test\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=32,\n",
        ")"
      ],
      "metadata": {
        "id": "BFsaQqeYpxqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "import tensorflow as tf\n",
        "\n",
        "num_train_steps = len(tf_train_dataset)\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=2e-5,\n",
        "    num_warmup_steps=1_000,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "# Train in mixed-precision float16\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "id": "8SRsx4zApxty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "eval_loss = model.evaluate(tf_eval_dataset)\n",
        "print(f\"Perplexity: {math.exp(eval_loss):.2f}\")"
      ],
      "metadata": {
        "id": "D-Nm3t38pxxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tf_train_dataset:\n",
        "    break\n",
        "print(len(i[1]))"
      ],
      "metadata": {
        "id": "CjxxZzL43-1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(tf_train_dataset, validation_data=tf_eval_dataset)"
      ],
      "metadata": {
        "id": "-q0BXCD3px08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_loss = model.evaluate(tf_eval_dataset)\n",
        "print(f\"Perplexity: {math.exp(eval_loss):.2f}\")"
      ],
      "metadata": {
        "id": "8jyCkyl5px4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.bert.paramerers.classifier"
      ],
      "metadata": {
        "id": "vKr21t964ohz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "mask_filler = pipeline(\n",
        "    \"fill-mask\", model=\"huggingface-course/distilbert-base-uncased-finetuned-imdb\"\n",
        ")"
      ],
      "metadata": {
        "id": "Q_mE5ndXpx7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = mask_filler(text)\n",
        "\n",
        "for pred in preds:\n",
        "    print(f\">>> {pred['sequence']}\")"
      ],
      "metadata": {
        "id": "jUHksHGBxYRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "-uCHlFSrxYT6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}